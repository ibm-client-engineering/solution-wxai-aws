"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[6679],{6796:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>a,toc:()=>c});var s=t(5893),r=t(1151);const i={id:"upi_install",sidebar_position:2,title:"UPI Installation Instructions",custom_edit_url:null},o=void 0,a={id:"Deployment/upi_install",title:"UPI Installation Instructions",description:"Prepare the Bastion Node",source:"@site/docs/2-Deployment/2-UPI_Install.mdx",sourceDirName:"2-Deployment",slug:"/Deployment/upi_install",permalink:"/solution-wxai-aws/Deployment/upi_install",draft:!1,unlisted:!1,editUrl:null,tags:[],version:"current",sidebarPosition:2,frontMatter:{id:"upi_install",sidebar_position:2,title:"UPI Installation Instructions",custom_edit_url:null},sidebar:"tutorialSidebar",previous:{title:"Preparation Steps",permalink:"/solution-wxai-aws/Deployment/preparation"},next:{title:"Installation",permalink:"/solution-wxai-aws/installation"}},l={},c=[{value:"Prepare the Bastion Node",id:"prepare-the-bastion-node",level:3},{value:"Update the OS and install additional tools",id:"update-the-os-and-install-additional-tools",level:4},{value:"Clone the repository to the bootnode.",id:"clone-the-repository-to-the-bootnode",level:4},{value:"Run &#39;setup_bastion&#39; script",id:"run-setup_bastion-script",level:4},{value:"Change the bootnode hostname to &#39;registry.$DOMAIN&#39;",id:"change-the-bootnode-hostname-to-registrydomain",level:4},{value:"Setup Services",id:"setup-services",level:3},{value:"Create Registry",id:"create-registry",level:4},{value:"Start the registry",id:"start-the-registry",level:4},{value:"Add your local registry login details",id:"add-your-local-registry-login-details",level:4},{value:"Add your details to the auth.json",id:"add-your-details-to-the-authjson",level:4},{value:"Setup Local and Internal registries",id:"setup-local-and-internal-registries",level:3},{value:"Load the registry with the OCP files",id:"load-the-registry-with-the-ocp-files",level:4},{value:"Extract the OpenShift Installer",id:"extract-the-openshift-installer",level:4},{value:"Start cluster creation",id:"start-cluster-creation",level:3},{value:"Collect information for &#39;config.sh&#39;",id:"collect-information-for-configsh",level:4},{value:"Start the installation",id:"start-the-installation",level:4},{value:"NFS Provisioner setup",id:"nfs-provisioner-setup",level:2},{value:"Creating the EFS filesystem",id:"creating-the-efs-filesystem",level:3},{value:"Create mount targets:",id:"create-mount-targets",level:4},{value:"Deploying the provisioner with a yaml",id:"deploying-the-provisioner-with-a-yaml",level:3},{value:"Download nfs-provisioner.yml",id:"download-nfs-provisioneryml",level:4},{value:"Apply nfs_provisioner.yml",id:"apply-nfs_provisioneryml",level:4},{value:"Deploying the provisioner with helm",id:"deploying-the-provisioner-with-helm",level:3},{value:"Installing helm",id:"installing-helm",level:4},{value:"Install to OCP",id:"install-to-ocp",level:3},{value:"Install the helm chart and run the helm install",id:"install-the-helm-chart-and-run-the-helm-install",level:3},{value:"Change Cluster Domain",id:"change-cluster-domain",level:2},{value:"Generate new self-signed certificate",id:"generate-new-self-signed-certificate",level:3},{value:"Generate CA certs",id:"generate-ca-certs",level:4},{value:"Generate Server certs",id:"generate-server-certs",level:4},{value:"Update the cluster:",id:"update-the-cluster",level:4},{value:"Increase Primary Disk size on worker nodes:",id:"increase-primary-disk-size-on-worker-nodes",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",...(0,r.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h3,{id:"prepare-the-bastion-node",children:"Prepare the Bastion Node"}),"\n",(0,s.jsx)(n.h4,{id:"update-the-os-and-install-additional-tools",children:"Update the OS and install additional tools"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"sudo yum update -y; sudo yum install git -y\n"})}),"\n",(0,s.jsx)(n.h4,{id:"clone-the-repository-to-the-bootnode",children:"Clone the repository to the bootnode."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"git clone https://github.com/ibm-client-engineering/solution-wxai-aws\n"})}),"\n",(0,s.jsx)(n.h4,{id:"run-setup_bastion-script",children:"Run 'setup_bastion' script"}),"\n",(0,s.jsx)(n.p,{children:"Run the 'setup_bastion' script which will install additional tools, and configure an HTTP server to host the Bootstrap ignition file."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"cd $HOME/aws-openshift410-cloudformation-noIAM-noR53/utils\n./setup_bastion.sh\n"})}),"\n",(0,s.jsx)(n.h4,{id:"change-the-bootnode-hostname-to-registrydomain",children:"Change the bootnode hostname to 'registry.$DOMAIN'"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"sudo hostnamectl set-hostname registry.$DOMAIN.com\nsudo reboot\n"})}),"\n",(0,s.jsx)(n.h3,{id:"setup-services",children:"Setup Services"}),"\n",(0,s.jsx)(n.h4,{id:"create-registry",children:"Create Registry"}),"\n",(0,s.jsx)(n.p,{children:"Create a new directory for the registry, select a port (suggested port: 5000), a username and a password."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"sudo mkdir -p /ibm/\nsudo chown -R ec2-user:ec2-user /ibm/\n./create_registry.sh <registry_directory> <port> <userid> <password> <local_dir_install>\n"})}),"\n",(0,s.jsx)(n.p,{children:"Example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./create_registry.sh /ibm 5000 wxai CeFsm2024 /home/ec2-user/openshift-upi-master/aws-openshift410-cloudformation-noIAM-noR53\n"})}),"\n",(0,s.jsx)(n.h4,{id:"start-the-registry",children:"Start the registry"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./start_registry.sh <registry_directory> <port>\n"})}),"\n",(0,s.jsx)(n.p,{children:"Example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./start_registry.sh /ibm 5000\n"})}),"\n",(0,s.jsx)(n.h4,{id:"add-your-local-registry-login-details",children:"Add your local registry login details"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"mkdir -p /ibm/security/auth/\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"echo -n '<user_name>:<password>' | base64 -w0 \n"})}),"\n",(0,s.jsx)(n.h4,{id:"add-your-details-to-the-authjson",children:"Add your details to the auth.json"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'{\n  "auths": {\n    "<mirror_registry>": { \n      "auth": "<credentials>", \n      "email": "you@example.com"\n    }\n  }\n}\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"<mirror_registry> - the URL of the registry including the port\n<credentials> - the output from \"echo -n '<user_name>:<password>' | base64 -w0 \"\n"})}),"\n",(0,s.jsx)(n.p,{children:"Confirm the registry is accessible:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"podman login <Registry_URL> --authfile /ibm/security/auth/auth.json\n"})}),"\n",(0,s.jsx)(n.h3,{id:"setup-local-and-internal-registries",children:"Setup Local and Internal registries"}),"\n",(0,s.jsx)(n.h4,{id:"load-the-registry-with-the-ocp-files",children:"Load the registry with the OCP files"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./load_ocp.sh <ocprelease> <registryip:port> <contentpath> <authfile>\n"})}),"\n",(0,s.jsx)(n.p,{children:"Example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./load_ocp.sh 4.14.9 registry.cpdu8vscs.ibmworkshops.com:5000 /ibm/openshift-4.14.9/export /ibm/openshift/auth.json\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'export OCP_RELEASE="4.14.9"\n\nexport LOCAL_REGISTRY="registry.cpdu8vscs.ibmworkshops.com:5000"\n\nexport LOCAL_REPOSITORY="openshift"\n\nexport PRODUCT_REPO="openshift-release-dev"\n\nexport RELEASE_NAME="ocp-release"\n\nexport ARCHITECTURE="x86_64"\n\nexport REMOVABLE_MEDIA_PATH="/ibm/ocp-images"\n\nexport LOCAL_SECRET_JSON="/ibm/openshift/auth.json"\n\n\n'})}),"\n",(0,s.jsx)(n.p,{children:"Review images and configurations"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"oc adm release mirror -a ${LOCAL_SECRET_JSON} --from=quay.io/${PRODUCT_REPO}/${RELEASE_NAME}:${OCP_RELEASE}-${ARCHITECTURE} --to=${LOCAL_REGISTRY}/${LOCAL_REPOSITORY} --to-release-image=${LOCAL_REGISTRY}/${LOCAL_REPOSITORY}:${OCP_RELEASE}-${ARCHITECTURE} --dry-run\n"})}),"\n",(0,s.jsx)(n.p,{children:"Pull down images and send to local registry."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'oc image mirror -a ${LOCAL_SECRET_JSON} --from-dir=${REMOVABLE_MEDIA_PATH}/mirror "file://openshift/release:${OCP_RELEASE}*" ${LOCAL_REGISTRY}/${LOCAL_REPOSITORY} \n'})}),"\n",(0,s.jsx)(n.h4,{id:"extract-the-openshift-installer",children:"Extract the OpenShift Installer"}),"\n",(0,s.jsx)(n.p,{children:"Generate the openshift-install binary for the version of openshift images that were pulled."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'oc adm release extract -a ${LOCAL_SECRET_JSON} --command=openshift-install "${LOCAL_REGISTRY}/${LOCAL_REPOSITORY}:${OCP_RELEASE}-${ARCHITECTURE}"\n'})}),"\n",(0,s.jsx)(n.p,{children:"Move openshift-install to /usr/bin."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"sudo mv openshift-install /usr/bin/openshift-install\n"})}),"\n",(0,s.jsx)(n.h3,{id:"start-cluster-creation",children:"Start cluster creation"}),"\n",(0,s.jsx)(n.h4,{id:"collect-information-for-configsh",children:"Collect information for 'config.sh'"}),"\n",(0,s.jsx)(n.p,{children:"Information needed to update 'config.sh'"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Cluster Name\nBase Domain\nRegistry URL\nLocal Pull Secret updated with local registry auth.\nAdditional Trust certs generated during the registry creation process.\nAWS Region\nAWS Private Subnets\nAWS VPC ID\nAWS VPC CIDR\nAWS RHCOS AMI ID\n\nBootstrap allowed SSH CIDR\nBootstrap Ignition URL (Bastion node's hostname, port, and file name)\nMaster Instance Type\nWorker Count\nWorker Instance Type\n"})}),"\n",(0,s.jsx)(n.p,{children:"****Important Node: AWS CLI will need to be configured, and output format MUST be json"}),"\n",(0,s.jsx)(n.h4,{id:"start-the-installation",children:"Start the installation"}),"\n",(0,s.jsx)(n.p,{children:'After updating config.sh, run "create_cluster_step_1.sh".'}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./create_cluster_step_1.sh\n"})}),"\n",(0,s.jsx)(n.p,{children:"Once this completes, create the DNS records listed in the script output:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"api.{ClusterName}.{DOMAINNAME} -> wxai-int-(random_string).elb.us-east-2.amazonaws.com\napi-int.{ClusterName}.{DOMAINNAME} -> wxai-int-(random_string).elb.us-east-2.amazonaws.com\n*.apps.{ClusterName}.{DOMAINNAME} -> wxai-int-(random_string).elb.us-east-2.amazonaws.com\n"})}),"\n",(0,s.jsx)(n.p,{children:"Now run step 2:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./create_cluster_step_2.sh\n"})}),"\n",(0,s.jsx)(n.h2,{id:"nfs-provisioner-setup",children:"NFS Provisioner setup"}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsx)(n.p,{children:"In a user managed instance of OCP on AWS, the EFS provisioner from AWS is not available. In our case we will be provisioning an EFS share, and then installing the NFS provioner to the cluster.2a"})}),"\n",(0,s.jsx)(n.h3,{id:"creating-the-efs-filesystem",children:"Creating the EFS filesystem"}),"\n",(0,s.jsx)(n.p,{children:"Create an AWS Elastic File System with the following commands:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"export CREATION_TOKEN='ibm-wxai-token'\naws efs create-file-system --creation-token ${CREATION_TOKEN} --encrypted --backup --performance-mode generalPurpose --throughput-mode elastic --region us-east-2 --tags Key=key,Value=value Key=key1,Value=value1\n"})}),"\n",(0,s.jsx)(n.p,{children:"Set the Subnet IDs and Worker Security Group ID variables:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'export SUBNET_ID_1="US-EAST-2a Subnet ID"\nexport SUBNET_ID_2="US-EAST-2b Subnet ID"\nexport SUBNET_ID_3="US-EAST-2c Subnet ID"\nexport WORKER_SG="Worker Security Group ID"\nexport EFS_ID=$(aws efs describe-file-systems --creation-token ${CREATION_TOKEN} | jq \'.FileSystems[] | ."FileSystemId"\'| tr -d \'"\')\n'})}),"\n",(0,s.jsx)(n.h4,{id:"create-mount-targets",children:"Create mount targets:"}),"\n",(0,s.jsx)(n.p,{children:"Run the following commands to create mount targets that include the three subnets used by the worker nodes:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"aws efs create-mount-target --file-system-id ${EFS_ID} --subnet-id  ${SUBNET_ID_1} --security-group ${WORKER_SG_ID} --region us-east-2\naws efs create-mount-target --file-system-id ${EFS_ID} --subnet-id  ${SUBNET_ID_2} --security-group ${WORKER_SG_ID} --region us-east-2\naws efs create-mount-target --file-system-id ${EFS_ID} --subnet-id  ${SUBNET_ID_3} --security-group ${WORKER_SG_ID} --region us-east-2\n"})}),"\n",(0,s.jsx)(n.h3,{id:"deploying-the-provisioner-with-a-yaml",children:"Deploying the provisioner with a yaml"}),"\n",(0,s.jsx)(n.h4,{id:"download-nfs-provisioneryml",children:"Download nfs-provisioner.yml"}),"\n",(0,s.jsx)(n.p,{children:"Download the nfs-provisioner.yml file from here:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://raw.githubusercontent.com/ibm-client-engineering/solution-wxai-aws/main/static/scripts/nfs_provisioner.yml",children:"https://raw.githubusercontent.com/ibm-client-engineering/solution-wxai-aws/main/static/scripts/nfs_provisioner.yml"})}),"\n",(0,s.jsx)(n.p,{children:"Confirm that the \u201cEFS_ID\u201d is properly set from the previous step:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"echo $EFS_ID\n"})}),"\n",(0,s.jsx)(n.p,{children:"Then update the \u2018nfs_provisioner.yml\u2019 to use the new EFS ID:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'sed -i "s/EFS_ID/${EFS_ID}/g" nfs_provisioner.yml\n'})}),"\n",(0,s.jsx)(n.h4,{id:"apply-nfs_provisioneryml",children:"Apply nfs_provisioner.yml"}),"\n",(0,s.jsx)(n.p,{children:"Now create the nfs_provisioner in the cluster:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"oc create -f nfs_provisioner.yml\n"})}),"\n",(0,s.jsx)(n.h3,{id:"deploying-the-provisioner-with-helm",children:"Deploying the provisioner with helm"}),"\n",(0,s.jsx)(n.h4,{id:"installing-helm",children:"Installing helm"}),"\n",(0,s.jsx)(n.p,{children:"Verify and/or install openssl"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"sudo dnf -y install openssl\n"})}),"\n",(0,s.jsx)(n.p,{children:"Run the following commands to install helm to the bastion host"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\nchmod +x get_helm.sh\n./get_helm.sh\n\nDownloading https://get.helm.sh/helm-v3.14.3-linux-amd64.tar.gz\nVerifying checksum... Done.\nPreparing to install helm into /usr/local/bin\nhelm installed into /usr/local/bin/helm\n"})}),"\n",(0,s.jsx)(n.p,{children:"Verify helm is available"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:'helm\n\nThe Kubernetes package manager\n\nCommon actions for Helm:\n\n- helm search:    search for charts\n- helm pull:      download a chart to your local directory to view\n- helm install:   upload the chart to Kubernetes\n- helm list:      list releases of charts\n\nEnvironment variables:\n\n| Name                               | Description                                                                                                |\n|------------------------------------|------------------------------------------------------------------------------------------------------------|\n| $HELM_CACHE_HOME                   | set an alternative location for storing cached files.                                                      |\n| $HELM_CONFIG_HOME                  | set an alternative location for storing Helm configuration.                                                |\n| $HELM_DATA_HOME                    | set an alternative location for storing Helm data.                                                         |\n| $HELM_DEBUG                        | indicate whether or not Helm is running in Debug mode                                                      |\n| $HELM_DRIVER                       | set the backend storage driver. Values are: configmap, secret, memory, sql.                                |\n| $HELM_DRIVER_SQL_CONNECTION_STRING | set the connection string the SQL storage driver should use.                                               |\n| $HELM_MAX_HISTORY                  | set the maximum number of helm release history.                                                            |\n| $HELM_NAMESPACE                    | set the namespace used for the helm operations.                                                            |\n| $HELM_NO_PLUGINS                   | disable plugins. Set HELM_NO_PLUGINS=1 to disable plugins.                                                 |\n| $HELM_PLUGINS                      | set the path to the plugins directory                                                                      |\n| $HELM_REGISTRY_CONFIG              | set the path to the registry config file.                                                                  |\n| $HELM_REPOSITORY_CACHE             | set the path to the repository cache directory                                                             |\n| $HELM_REPOSITORY_CONFIG            | set the path to the repositories file.                                                                     |\n| $KUBECONFIG                        | set an alternative Kubernetes configuration file (default "~/.kube/config")                                |\n| $HELM_KUBEAPISERVER                | set the Kubernetes API Server Endpoint for authentication                                                  |\n| $HELM_KUBECAFILE                   | set the Kubernetes certificate authority file.                                                             |\n| $HELM_KUBEASGROUPS                 | set the Groups to use for impersonation using a comma-separated list.                                      |\n| $HELM_KUBEASUSER                   | set the Username to impersonate for the operation.                                                         |\n| $HELM_KUBECONTEXT                  | set the name of the kubeconfig context.                                                                    |\n| $HELM_KUBETOKEN                    | set the Bearer KubeToken used for authentication.                                                          |\n| $HELM_KUBEINSECURE_SKIP_TLS_VERIFY | indicate if the Kubernetes API server\'s certificate validation should be skipped (insecure)                |\n| $HELM_KUBETLS_SERVER_NAME          | set the server name used to validate the Kubernetes API server certificate                                 |\n| $HELM_BURST_LIMIT                  | set the default burst limit in the case the server contains many CRDs (default 100, -1 to disable)         |\n| $HELM_QPS                          | set the Queries Per Second in cases where a high number of calls exceed the option for higher burst values |\n\nHelm stores cache, configuration, and data based on the following configuration order:\n\n- If a HELM_*_HOME environment variable is set, it will be used\n- Otherwise, on systems supporting the XDG base directory specification, the XDG variables will be used\n- When no other location is set a default location will be used based on the operating system\n\nBy default, the default directories depend on the Operating System. The defaults are listed below:\n\n| Operating System | Cache Path                | Configuration Path             | Data Path               |\n|------------------|---------------------------|--------------------------------|-------------------------|\n| Linux            | $HOME/.cache/helm         | $HOME/.config/helm             | $HOME/.local/share/helm |\n| macOS            | $HOME/Library/Caches/helm | $HOME/Library/Preferences/helm | $HOME/Library/helm      |\n| Windows          | %TEMP%\\helm               | %APPDATA%\\helm                 | %APPDATA%\\helm          |\n\nUsage:\n  helm [command]\n\nAvailable Commands:\n  completion  generate autocompletion scripts for the specified shell\n  create      create a new chart with the given name\n  dependency  manage a chart\'s dependencies\n  env         helm client environment information\n  get         download extended information of a named release\n  help        Help about any command\n  history     fetch release history\n  install     install a chart\n  lint        examine a chart for possible issues\n  list        list releases\n  package     package a chart directory into a chart archive\n  plugin      install, list, or uninstall Helm plugins\n  pull        download a chart from a repository and (optionally) unpack it in local directory\n  push        push a chart to remote\n  registry    login to or logout from a registry\n  repo        add, list, remove, update, and index chart repositories\n  rollback    roll back a release to a previous revision\n  search      search for a keyword in charts\n  show        show information of a chart\n  status      display the status of the named release\n  template    locally render templates\n  test        run tests for a release\n  uninstall   uninstall a release\n  upgrade     upgrade a release\n  verify      verify that a chart at the given path has been signed and is valid\n  version     print the client version information\n\nFlags:\n      --burst-limit int                 client-side default throttling limit (default 100)\n      --debug                           enable verbose output\n  -h, --help                            help for helm\n      --kube-apiserver string           the address and the port for the Kubernetes API server\n      --kube-as-group stringArray       group to impersonate for the operation, this flag can be repeated to specify multiple groups.\n      --kube-as-user string             username to impersonate for the operation\n      --kube-ca-file string             the certificate authority file for the Kubernetes API server connection\n      --kube-context string             name of the kubeconfig context to use\n      --kube-insecure-skip-tls-verify   if true, the Kubernetes API server\'s certificate will not be checked for validity. This will make your HTTPS connections insecure\n      --kube-tls-server-name string     server name to use for Kubernetes API server certificate validation. If it is not provided, the hostname used to contact the server is used\n      --kube-token string               bearer token used for authentication\n      --kubeconfig string               path to the kubeconfig file\n  -n, --namespace string                namespace scope for this request\n      --qps float32                     queries per second used when communicating with the Kubernetes API, not including bursting\n      --registry-config string          path to the registry config file (default "/home/kramerro/.config/helm/registry/config.json")\n      --repository-cache string         path to the file containing cached repository indexes (default "/home/kramerro/.cache/helm/repository")\n      --repository-config string        path to the file containing repository names and URLs (default "/home/kramerro/.config/helm/repositories.yaml")\n\nUse "helm [command] --help" for more information about a command.\n'})}),"\n",(0,s.jsx)(n.h3,{id:"install-to-ocp",children:"Install to OCP"}),"\n",(0,s.jsx)(n.p,{children:"From the OC cli:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:'oc new-project nfs-provisioner\n\nNow using project "nfs-provisioner" on server "https://api.wxai.cpdu8vscs.ibmworkshops.com:6443".\n\nYou can add applications to this project with the \'new-app\' command. For example, try:\n\n    oc new-app rails-postgresql-example\n\nto build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:\n\n    kubectl create deployment hello-node --image=registry.k8s.io/e2e-test-images/agnhost:2.43 -- /agnhost serve-hostname\n'})}),"\n",(0,s.jsx)(n.p,{children:"This will automatically put you in that project."}),"\n",(0,s.jsx)(n.p,{children:"Now set up the SCCs"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"oc apply -f - <<EOF\nallowHostDirVolumePlugin: true\nallowHostIPC: false\nallowHostNetwork: false\nallowHostPID: false\nallowHostPorts: false\nallowPrivilegeEscalation: true\nallowPrivilegedContainer: false\nallowedCapabilities: null\napiVersion: security.openshift.io/v1\ndefaultAddCapabilities: null\nfsGroup:\n  type: RunAsAny\ngroups: []\nkind: SecurityContextConstraints\nmetadata:\n  annotations:\n    kubernetes.io/description: 'hostmount-anyuid provides all the features of the\n      restricted SCC but allows host mounts and any UID by a pod.  This is primarily\n      used by the persistent volume recycler. WARNING: this SCC allows host file system\n      access as any UID, including UID 0.  Grant with caution.'\n  name: nfs-storage-hostmount-anyuid\nreadOnlyRootFilesystem: false\nrequiredDropCapabilities:\n- MKNOD\nrunAsUser:\n  type: RunAsAny\nseLinuxContext:\n  type: MustRunAs\nsupplementalGroups:\n  type: RunAsAny\nusers:\n- system:serviceaccount:nfs-provisioner:nfs-subdir-external-provisioner\nvolumes:\n- configMap\n- downwardAPI\n- emptyDir\n- hostPath\n- nfs\n- persistentVolumeClaim\n- projected\n- secret\nEOF\n"})}),"\n",(0,s.jsx)(n.p,{children:"output:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"securitycontextconstraints.security.openshift.io/nfs-storage-hostmount-anyuid created\n"})}),"\n",(0,s.jsx)(n.h3,{id:"install-the-helm-chart-and-run-the-helm-install",children:"Install the helm chart and run the helm install"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"<EFS URL>"})," should be returned by the aws cli creation of the EFS storage filesystem."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/\nhelm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \\\n    --namespace nfs-provisioner \\\n    --set nfs.server=<EFS URL>\\\n    --set nfs.path=/ \\\n    --set storageClass.defaultClass=true\n"})}),"\n",(0,s.jsx)(n.p,{children:"Verify the pods are up"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"oc get pods\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.em,{children:"EXAMPLE RETURNED OUTPUT HERE"})}),"\n",(0,s.jsx)(n.p,{children:"Make sure the storage class now exists and is set to default"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"oc get sc\n"})}),"\n",(0,s.jsx)(n.p,{children:"Verify that the storage will provision with the following test deployment"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:'oc apply -f - <<EOF\nkind: Pod\napiVersion: v1\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: test-pod\n    image: busybox:stable\n    command:\n      - "/bin/sh"\n    args:\n      - "-c"\n      - "touch /mnt/SUCCESS && exit 0 || exit 1"\n    volumeMounts:\n      - name: nfs-pvc\n        mountPath: "/mnt"\n  restartPolicy: "Never"\n  volumes:\n    - name: nfs-pvc\n      persistentVolumeClaim:\n        claimName: test-claim\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: test-claim\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 1Mi\nEOF\n\n'})}),"\n",(0,s.jsx)(n.h2,{id:"change-cluster-domain",children:"Change Cluster Domain"}),"\n",(0,s.jsx)(n.h3,{id:"generate-new-self-signed-certificate",children:"Generate new self-signed certificate"}),"\n",(0,s.jsx)(n.h4,{id:"generate-ca-certs",children:"Generate CA certs"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'openssl genrsa -out ca.key 2048\n\nopenssl req -new -x509 -days 365 -key ca.key -subj "/C=CN/ST=GD/L=SZ/O=Acme, Inc./CN=Acme Root CA" -out ca.crt\n\n'})}),"\n",(0,s.jsx)(n.h4,{id:"generate-server-certs",children:"Generate Server certs"}),"\n",(0,s.jsx)(n.p,{children:"Generate 'server.csr'"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'openssl req -newkey rsa:2048 -nodes -keyout server.key -subj "/C=CN/ST=GD/L=SZ/O=Acme, Inc./CN=*.{BASE_DOMAIN}" -out server.csr\n'})}),"\n",(0,s.jsx)(n.p,{children:"Generate 'server.crt'"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'openssl x509 -req -extfile <(printf "subjectAltName=DNS:*.{BASE_DOMAIN}") -days 365 -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt\n'})}),"\n",(0,s.jsx)(n.h4,{id:"update-the-cluster",children:"Update the cluster:"}),"\n",(0,s.jsx)(n.p,{children:"Create the new secret which will contain the cert and key:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"oc create secret tls custom-cert --cert=server.crt --key=server.key -n openshift-config\n"})}),"\n",(0,s.jsx)(n.p,{children:"Update the ingress:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"oc edit ingresses.config/cluster -o yaml\n"})}),"\n",(0,s.jsx)(n.p,{children:"Add the following under 'spec:'"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"  componentRoutes:\n  - hostname: console.{NEW_URL}\n    name: console\n    namespace: openshift-console\n    servingCertKeyPairSecret:\n      name: custom-cert\n  - hostname: oauth.{NEW_URL}\n    name: oauth-openshift\n    namespace: openshift-authentication\n    servingCertKeyPairSecret:\n      name: custom-cert\n"})}),"\n",(0,s.jsx)(n.h2,{id:"increase-primary-disk-size-on-worker-nodes",children:"Increase Primary Disk size on worker nodes:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"Run the following bash one-liner to increase the primary disk on all worker nodes to 500GB:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"aws ec2 describe-instances --query 'Reservations[*].Instances[*].[InstanceId,Tags[?Key==`Name`].Value|[0],BlockDeviceMappings[0].Ebs.VolumeId]' --output text | grep worker | awk '{print $3}' | while read volume_id; do aws ec2 modify-volume --volume-id $volume_id --size 500; done\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsx)(n.li,{children:"Log into the node with following command:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"oc debug node/<node_name>\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"3",children:["\n",(0,s.jsx)(n.li,{children:"Once in the node, run the following:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"chroot /host\n"})}),"\n",(0,s.jsx)(n.p,{children:"then:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"sudo lsblk\n"})}),"\n",(0,s.jsx)(n.p,{children:"The output should look like this:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"# sudo lsblk\nNAME        MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\nnvme1n1     259:0    0     1T  0 disk\nnvme0n1     259:1    0   500G  0 disk\n|-nvme0n1p1 259:2    0     1M  0 part\n|-nvme0n1p2 259:3    0   127M  0 part\n|-nvme0n1p3 259:4    0   384M  0 part /boot\n`-nvme0n1p4 259:5    0 239.5G  0 part /var/lib/kubelet/pods/555d6f90-41fd-49d2-8aad-fa7293a924e4/volume-subpaths/app-config-override/wd-discovery-cnm-api/2\n                                      /var/lib/kubelet/pods/57d28f73-d355-4092-8e52-6b6aeec28bd5/volume-subpaths/clouseau-config/search/4\n                                      /var/lib/kubelet/pods/fcb4b5ec-ea1a-42c7-908c-a027cf885ca1/volume-subpaths/db2wh-cm/zen-database-core/1\n                                      /var/lib/kubelet/pods/fcb4b5ec-ea1a-42c7-908c-a027cf885ca1/volume-subpaths/db2oltp-cm/zen-database-core/0\n                                      /var/lib/kubelet/pods/5e35fe3f-7e4d-4729-b3dd-b9553ffd73f6/volume-subpaths/nginx-conf/monitoring-plugin/1\n                                      /var\n                                      /sysroot/ostree/deploy/rhcos/var\n                                      /sysroot\n                                      /usr\n                                      /etc\n                                      /\n\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"4",children:["\n",(0,s.jsx)(n.li,{children:"Find the part on the disk that you wish to increase, in my case it was 'nvme0n1p4'."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Now we extend the partition, by targeting the disk (Example: /dev/nvme0n1) and the partition (Example: 4)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"sudo growpart /dev/nvme0n1 4\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"5",children:["\n",(0,s.jsx)(n.li,{children:"Check the disk sizes again:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"sudo lsblk\n"})}),"\n",(0,s.jsx)(n.p,{children:"This is what my output looks like now:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"NAME        MAJ:MIN RM   SIZE RO TYPE MOUNTPOINTS\nnvme1n1     259:0    0     1T  0 disk\nnvme0n1     259:1    0   500G  0 disk\n|-nvme0n1p1 259:2    0     1M  0 part\n|-nvme0n1p2 259:3    0   127M  0 part\n|-nvme0n1p3 259:4    0   384M  0 part /boot\n`-nvme0n1p4 259:5    0 499.5G  0 part /var/lib/kubelet/pods/555d6f90-41fd-49d2-8aad-fa7293a924e4/volume-subpaths/app-config-override/wd-discovery-cnm-api/2\n                                      /var/lib/kubelet/pods/57d28f73-d355-4092-8e52-6b6aeec28bd5/volume-subpaths/clouseau-config/search/4\n                                      /var/lib/kubelet/pods/fcb4b5ec-ea1a-42c7-908c-a027cf885ca1/volume-subpaths/db2wh-cm/zen-database-core/1\n                                      /var/lib/kubelet/pods/fcb4b5ec-ea1a-42c7-908c-a027cf885ca1/volume-subpaths/db2oltp-cm/zen-database-core/0\n                                      /var/lib/kubelet/pods/5e35fe3f-7e4d-4729-b3dd-b9553ffd73f6/volume-subpaths/nginx-conf/monitoring-plugin/1\n                                      /var\n                                      /sysroot/ostree/deploy/rhcos/var\n                                      /sysroot\n                                      /usr\n                                      /etc\n                                      /\n"})}),"\n",(0,s.jsxs)(n.ol,{start:"6",children:["\n",(0,s.jsx)(n.li,{children:"Last step is to extend the file system:"}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"sudo xfs_growfs -d /\n"})})]})}function h(e={}){const{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},1151:(e,n,t)=>{t.d(n,{Z:()=>a,a:()=>o});var s=t(7294);const r={},i=s.createContext(r);function o(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);