"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[6679],{6796:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>a,toc:()=>h});var s=t(5893),i=t(1151);const r={id:"upi_install",sidebar_position:2,title:"UPI Installation Instructions",custom_edit_url:null},o=void 0,a={id:"Deployment/upi_install",title:"UPI Installation Instructions",description:"Prepare the Bastion Node",source:"@site/docs/2-Deployment/2-UPI_Install.mdx",sourceDirName:"2-Deployment",slug:"/Deployment/upi_install",permalink:"/solution-wxai-aws/Deployment/upi_install",draft:!1,unlisted:!1,editUrl:null,tags:[],version:"current",sidebarPosition:2,frontMatter:{id:"upi_install",sidebar_position:2,title:"UPI Installation Instructions",custom_edit_url:null},sidebar:"tutorialSidebar",previous:{title:"Installation",permalink:"/solution-wxai-aws/Deployment/installation"},next:{title:"Installation",permalink:"/solution-wxai-aws/installation"}},l={},h=[{value:"Prepare the Bastion Node",id:"prepare-the-bastion-node",level:3},{value:"Update the OS and install additional tools",id:"update-the-os-and-install-additional-tools",level:4},{value:"Clone the repository to the bootnode.",id:"clone-the-repository-to-the-bootnode",level:4},{value:"Run &#39;setup_bastion&#39; script",id:"run-setup_bastion-script",level:4},{value:"Change the bootnode hostname to &#39;registry.$DOMAIN&#39;",id:"change-the-bootnode-hostname-to-registrydomain",level:4},{value:"Setup Services",id:"setup-services",level:3},{value:"Create Registry",id:"create-registry",level:4},{value:"Start the registry",id:"start-the-registry",level:4},{value:"Add your local registry login details",id:"add-your-local-registry-login-details",level:4},{value:"Add your details to the auth.json",id:"add-your-details-to-the-authjson",level:4},{value:"Setup Local and Internal registries",id:"setup-local-and-internal-registries",level:3},{value:"Load the registry with the OCP files",id:"load-the-registry-with-the-ocp-files",level:4},{value:"Extract the OpenShift Installer",id:"extract-the-openshift-installer",level:4},{value:"Start cluster creation",id:"start-cluster-creation",level:3},{value:"Collect information for &#39;config.sh&#39;",id:"collect-information-for-configsh",level:4},{value:"Start the installation",id:"start-the-installation",level:4},{value:"NFS Provisioner setup",id:"nfs-provisioner-setup",level:2},{value:"Creating the EFS filesystem",id:"creating-the-efs-filesystem",level:3},{value:"Deploying the provisioner with helm",id:"deploying-the-provisioner-with-helm",level:3},{value:"Installing helm",id:"installing-helm",level:4},{value:"Install to OCP",id:"install-to-ocp",level:3},{value:"Install the helm chart and run the helm install",id:"install-the-helm-chart-and-run-the-helm-install",level:3}];function c(e){const n={admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h3,{id:"prepare-the-bastion-node",children:"Prepare the Bastion Node"}),"\n",(0,s.jsx)(n.h4,{id:"update-the-os-and-install-additional-tools",children:"Update the OS and install additional tools"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"sudo yum update -y; sudo yum install git -y\n"})}),"\n",(0,s.jsx)(n.h4,{id:"clone-the-repository-to-the-bootnode",children:"Clone the repository to the bootnode."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"git clone https://github.com/ibm-client-engineering/solution-wxai-aws\n"})}),"\n",(0,s.jsx)(n.h4,{id:"run-setup_bastion-script",children:"Run 'setup_bastion' script"}),"\n",(0,s.jsx)(n.p,{children:"Run the 'setup_bastion' script which will install additional tools, and configure an HTTP server to host the Bootstrap ignition file."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"cd $HOME/aws-openshift410-cloudformation-noIAM-noR53/utils\n./setup_bastion.sh\n"})}),"\n",(0,s.jsx)(n.h4,{id:"change-the-bootnode-hostname-to-registrydomain",children:"Change the bootnode hostname to 'registry.$DOMAIN'"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"sudo hostnamectl set-hostname registry.$DOMAIN.com\nsudo reboot\n"})}),"\n",(0,s.jsx)(n.h3,{id:"setup-services",children:"Setup Services"}),"\n",(0,s.jsx)(n.h4,{id:"create-registry",children:"Create Registry"}),"\n",(0,s.jsx)(n.p,{children:"Create a new directory for the registry, select a port (suggested port: 5000), a username and a password."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"sudo mkdir -p /ibm/\nsudo chown -R ec2-user:ec2-user /ibm/\n./create_registry.sh <registry_directory> <port> <userid> <password> <local_dir_install>\n"})}),"\n",(0,s.jsx)(n.p,{children:"Example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./create_registry.sh /ibm 5000 wxai CeFsm2024 /home/ec2-user/openshift-upi-master/aws-openshift410-cloudformation-noIAM-noR53\n"})}),"\n",(0,s.jsx)(n.h4,{id:"start-the-registry",children:"Start the registry"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./start_registry.sh <registry_directory> <port>\n"})}),"\n",(0,s.jsx)(n.p,{children:"Example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./start_registry.sh /ibm 5000\n"})}),"\n",(0,s.jsx)(n.h4,{id:"add-your-local-registry-login-details",children:"Add your local registry login details"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"mkdir -p /ibm/security/auth/\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"echo -n '<user_name>:<password>' | base64 -w0 \n"})}),"\n",(0,s.jsx)(n.h4,{id:"add-your-details-to-the-authjson",children:"Add your details to the auth.json"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'{\n  "auths": {\n    "<mirror_registry>": { \n      "auth": "<credentials>", \n      "email": "you@example.com"\n    }\n  }\n}\n'})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"<mirror_registry> - the URL of the registry including the port\n<credentials> - the output from \"echo -n '<user_name>:<password>' | base64 -w0 \"\n"})}),"\n",(0,s.jsx)(n.p,{children:"Confirm the registry is accessible:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"podman login <Registry_URL> --authfile /ibm/security/auth/auth.json\n"})}),"\n",(0,s.jsx)(n.h3,{id:"setup-local-and-internal-registries",children:"Setup Local and Internal registries"}),"\n",(0,s.jsx)(n.h4,{id:"load-the-registry-with-the-ocp-files",children:"Load the registry with the OCP files"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./load_ocp.sh <ocprelease> <registryip:port> <contentpath> <authfile>\n"})}),"\n",(0,s.jsx)(n.p,{children:"Example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./load_ocp.sh 4.14.9 registry.cpdu8vscs.ibmworkshops.com:5000 /ibm/openshift-4.14.9/export /ibm/openshift/auth.json\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'export OCP_RELEASE="4.14.9"\n\nexport LOCAL_REGISTRY="registry.cpdu8vscs.ibmworkshops.com:5000"\n\nexport LOCAL_REPOSITORY="openshift"\n\nexport PRODUCT_REPO="openshift-release-dev"\n\nexport RELEASE_NAME="ocp-release"\n\nexport ARCHITECTURE="x86_64"\n\nexport REMOVABLE_MEDIA_PATH="/ibm/ocp-images"\n\nexport LOCAL_SECRET_JSON="/ibm/openshift/auth.json"\n\n\n'})}),"\n",(0,s.jsx)(n.p,{children:"Review images and configurations"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"oc adm release mirror -a ${LOCAL_SECRET_JSON} --from=quay.io/${PRODUCT_REPO}/${RELEASE_NAME}:${OCP_RELEASE}-${ARCHITECTURE} --to=${LOCAL_REGISTRY}/${LOCAL_REPOSITORY} --to-release-image=${LOCAL_REGISTRY}/${LOCAL_REPOSITORY}:${OCP_RELEASE}-${ARCHITECTURE} --dry-run\n"})}),"\n",(0,s.jsx)(n.p,{children:"Pull down images and send to local registry."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'oc image mirror -a ${LOCAL_SECRET_JSON} --from-dir=${REMOVABLE_MEDIA_PATH}/mirror "file://openshift/release:${OCP_RELEASE}*" ${LOCAL_REGISTRY}/${LOCAL_REPOSITORY} \n'})}),"\n",(0,s.jsx)(n.h4,{id:"extract-the-openshift-installer",children:"Extract the OpenShift Installer"}),"\n",(0,s.jsx)(n.p,{children:"Generate the openshift-install binary for the version of openshift images that were pulled."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'oc adm release extract -a ${LOCAL_SECRET_JSON} --command=openshift-install "${LOCAL_REGISTRY}/${LOCAL_REPOSITORY}:${OCP_RELEASE}-${ARCHITECTURE}"\n'})}),"\n",(0,s.jsx)(n.p,{children:"Move openshift-install to /usr/bin."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"sudo mv openshift-install /usr/bin/openshift-install\n"})}),"\n",(0,s.jsx)(n.h3,{id:"start-cluster-creation",children:"Start cluster creation"}),"\n",(0,s.jsx)(n.h4,{id:"collect-information-for-configsh",children:"Collect information for 'config.sh'"}),"\n",(0,s.jsx)(n.p,{children:"Information needed to update 'config.sh'"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"Cluster Name\nBase Domain\nRegistry URL\nLocal Pull Secret updated with local registry auth.\nAdditional Trust certs generated during the registry creation process.\nAWS Region\nAWS Private Subnets\nAWS VPC ID\nAWS VPC CIDR\nAWS RHCOS AMI ID\n\nBootstrap allowed SSH CIDR\nBootstrap Ignition URL (Bastion node's hostname, port, and file name)\nMaster Instance Type\nWorker Count\nWorker Instance Type\n"})}),"\n",(0,s.jsx)(n.p,{children:"****Important Node: AWS CLI will need to be configured, and output format MUST be json"}),"\n",(0,s.jsx)(n.h4,{id:"start-the-installation",children:"Start the installation"}),"\n",(0,s.jsx)(n.p,{children:'After updating config.sh, run "create_cluster_step_1.sh".'}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./create_cluster_step_1.sh\n"})}),"\n",(0,s.jsx)(n.p,{children:"Once this completes, create the DNS records listed in the script output:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"api.{ClusterName}.{DOMAINNAME} -> wxai-int-(random_string).elb.us-east-2.amazonaws.com\napi-int.{ClusterName}.{DOMAINNAME} -> wxai-int-(random_string).elb.us-east-2.amazonaws.com\n*.apps.{ClusterName}.{DOMAINNAME} -> wxai-int-(random_string).elb.us-east-2.amazonaws.com\n"})}),"\n",(0,s.jsx)(n.p,{children:"Now run step 2:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"./create_cluster_step_2.sh\n"})}),"\n",(0,s.jsx)(n.h2,{id:"nfs-provisioner-setup",children:"NFS Provisioner setup"}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsx)(n.p,{children:"In a user managed instance of OCP on AWS, the EFS provisioner from AWS is not available. In our case we will be provisioning an EFS share, and then installing the NFS provioner to the cluster.2a"})}),"\n",(0,s.jsx)(n.h3,{id:"creating-the-efs-filesystem",children:"Creating the EFS filesystem"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"commands in AWS CLI to deploy an EFS filesystem"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"deploying-the-provisioner-with-helm",children:"Deploying the provisioner with helm"}),"\n",(0,s.jsx)(n.h4,{id:"installing-helm",children:"Installing helm"}),"\n",(0,s.jsx)(n.p,{children:"Verify and/or install openssl"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"sudo dnf -y install openssl\n"})}),"\n",(0,s.jsx)(n.p,{children:"Run the following commands to install helm to the bastion host"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3\nchmod +x get_helm.sh\n./get_helm.sh\n"})}),"\n",(0,s.jsx)(n.p,{children:"Verify helm is available"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:'helm\n\nThe Kubernetes package manager\n\nCommon actions for Helm:\n\n- helm search:    search for charts\n- helm pull:      download a chart to your local directory to view\n- helm install:   upload the chart to Kubernetes\n- helm list:      list releases of charts\n\nEnvironment variables:\n\n| Name                               | Description                                                                                                |\n|------------------------------------|------------------------------------------------------------------------------------------------------------|\n| $HELM_CACHE_HOME                   | set an alternative location for storing cached files.                                                      |\n| $HELM_CONFIG_HOME                  | set an alternative location for storing Helm configuration.                                                |\n| $HELM_DATA_HOME                    | set an alternative location for storing Helm data.                                                         |\n| $HELM_DEBUG                        | indicate whether or not Helm is running in Debug mode                                                      |\n| $HELM_DRIVER                       | set the backend storage driver. Values are: configmap, secret, memory, sql.                                |\n| $HELM_DRIVER_SQL_CONNECTION_STRING | set the connection string the SQL storage driver should use.                                               |\n| $HELM_MAX_HISTORY                  | set the maximum number of helm release history.                                                            |\n| $HELM_NAMESPACE                    | set the namespace used for the helm operations.                                                            |\n| $HELM_NO_PLUGINS                   | disable plugins. Set HELM_NO_PLUGINS=1 to disable plugins.                                                 |\n| $HELM_PLUGINS                      | set the path to the plugins directory                                                                      |\n| $HELM_REGISTRY_CONFIG              | set the path to the registry config file.                                                                  |\n| $HELM_REPOSITORY_CACHE             | set the path to the repository cache directory                                                             |\n| $HELM_REPOSITORY_CONFIG            | set the path to the repositories file.                                                                     |\n| $KUBECONFIG                        | set an alternative Kubernetes configuration file (default "~/.kube/config")                                |\n| $HELM_KUBEAPISERVER                | set the Kubernetes API Server Endpoint for authentication                                                  |\n| $HELM_KUBECAFILE                   | set the Kubernetes certificate authority file.                                                             |\n| $HELM_KUBEASGROUPS                 | set the Groups to use for impersonation using a comma-separated list.                                      |\n| $HELM_KUBEASUSER                   | set the Username to impersonate for the operation.                                                         |\n| $HELM_KUBECONTEXT                  | set the name of the kubeconfig context.                                                                    |\n| $HELM_KUBETOKEN                    | set the Bearer KubeToken used for authentication.                                                          |\n| $HELM_KUBEINSECURE_SKIP_TLS_VERIFY | indicate if the Kubernetes API server\'s certificate validation should be skipped (insecure)                |\n| $HELM_KUBETLS_SERVER_NAME          | set the server name used to validate the Kubernetes API server certificate                                 |\n| $HELM_BURST_LIMIT                  | set the default burst limit in the case the server contains many CRDs (default 100, -1 to disable)         |\n| $HELM_QPS                          | set the Queries Per Second in cases where a high number of calls exceed the option for higher burst values |\n\nHelm stores cache, configuration, and data based on the following configuration order:\n\n- If a HELM_*_HOME environment variable is set, it will be used\n- Otherwise, on systems supporting the XDG base directory specification, the XDG variables will be used\n- When no other location is set a default location will be used based on the operating system\n\nBy default, the default directories depend on the Operating System. The defaults are listed below:\n\n| Operating System | Cache Path                | Configuration Path             | Data Path               |\n|------------------|---------------------------|--------------------------------|-------------------------|\n| Linux            | $HOME/.cache/helm         | $HOME/.config/helm             | $HOME/.local/share/helm |\n| macOS            | $HOME/Library/Caches/helm | $HOME/Library/Preferences/helm | $HOME/Library/helm      |\n| Windows          | %TEMP%\\helm               | %APPDATA%\\helm                 | %APPDATA%\\helm          |\n\nUsage:\n  helm [command]\n\nAvailable Commands:\n  completion  generate autocompletion scripts for the specified shell\n  create      create a new chart with the given name\n  dependency  manage a chart\'s dependencies\n  env         helm client environment information\n  get         download extended information of a named release\n  help        Help about any command\n  history     fetch release history\n  install     install a chart\n  lint        examine a chart for possible issues\n  list        list releases\n  package     package a chart directory into a chart archive\n  plugin      install, list, or uninstall Helm plugins\n  pull        download a chart from a repository and (optionally) unpack it in local directory\n  push        push a chart to remote\n  registry    login to or logout from a registry\n  repo        add, list, remove, update, and index chart repositories\n  rollback    roll back a release to a previous revision\n  search      search for a keyword in charts\n  show        show information of a chart\n  status      display the status of the named release\n  template    locally render templates\n  test        run tests for a release\n  uninstall   uninstall a release\n  upgrade     upgrade a release\n  verify      verify that a chart at the given path has been signed and is valid\n  version     print the client version information\n\nFlags:\n      --burst-limit int                 client-side default throttling limit (default 100)\n      --debug                           enable verbose output\n  -h, --help                            help for helm\n      --kube-apiserver string           the address and the port for the Kubernetes API server\n      --kube-as-group stringArray       group to impersonate for the operation, this flag can be repeated to specify multiple groups.\n      --kube-as-user string             username to impersonate for the operation\n      --kube-ca-file string             the certificate authority file for the Kubernetes API server connection\n      --kube-context string             name of the kubeconfig context to use\n      --kube-insecure-skip-tls-verify   if true, the Kubernetes API server\'s certificate will not be checked for validity. This will make your HTTPS connections insecure\n      --kube-tls-server-name string     server name to use for Kubernetes API server certificate validation. If it is not provided, the hostname used to contact the server is used\n      --kube-token string               bearer token used for authentication\n      --kubeconfig string               path to the kubeconfig file\n  -n, --namespace string                namespace scope for this request\n      --qps float32                     queries per second used when communicating with the Kubernetes API, not including bursting\n      --registry-config string          path to the registry config file (default "/home/kramerro/.config/helm/registry/config.json")\n      --repository-cache string         path to the file containing cached repository indexes (default "/home/kramerro/.cache/helm/repository")\n      --repository-config string        path to the file containing repository names and URLs (default "/home/kramerro/.config/helm/repositories.yaml")\n\nUse "helm [command] --help" for more information about a command.\n'})}),"\n",(0,s.jsx)(n.h3,{id:"install-to-ocp",children:"Install to OCP"}),"\n",(0,s.jsx)(n.p,{children:"From the OC cli:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"oc new-project nfs-provisioner\n"})}),"\n",(0,s.jsx)(n.p,{children:"This will automatically put you in that project."}),"\n",(0,s.jsx)(n.p,{children:"Now set up the SCCs"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"oc apply -f - <<EOF\nallowHostDirVolumePlugin: true\nallowHostIPC: false\nallowHostNetwork: false\nallowHostPID: false\nallowHostPorts: false\nallowPrivilegeEscalation: true\nallowPrivilegedContainer: false\nallowedCapabilities: null\napiVersion: security.openshift.io/v1\ndefaultAddCapabilities: null\nfsGroup:\n  type: RunAsAny\ngroups: []\nkind: SecurityContextConstraints\nmetadata:\n  annotations:\n    kubernetes.io/description: 'hostmount-anyuid provides all the features of the\n      restricted SCC but allows host mounts and any UID by a pod.  This is primarily\n      used by the persistent volume recycler. WARNING: this SCC allows host file system\n      access as any UID, including UID 0.  Grant with caution.'\n  name: nfs-storage-hostmount-anyuid\nreadOnlyRootFilesystem: false\nrequiredDropCapabilities:\n- MKNOD\nrunAsUser:\n  type: RunAsAny\nseLinuxContext:\n  type: MustRunAs\nsupplementalGroups:\n  type: RunAsAny\nusers:\n- system:serviceaccount:nfs-provisioner:nfs-subdir-external-provisioner\nvolumes:\n- configMap\n- downwardAPI\n- emptyDir\n- hostPath\n- nfs\n- persistentVolumeClaim\n- projected\n- secret\nEOF\n"})}),"\n",(0,s.jsx)(n.h3,{id:"install-the-helm-chart-and-run-the-helm-install",children:"Install the helm chart and run the helm install"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"<EFS URL>"})," should be returned by the aws cli creation of the EFS storage filesystem."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"helm repo add nfs-subdir-external-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/\nhelm install nfs-subdir-external-provisioner nfs-subdir-external-provisioner/nfs-subdir-external-provisioner \\\n    --namespace nfs-provisioner \\\n    --set nfs.server=<EFS URL>\\\n    --set nfs.path=/ \\\n    --set storageClass.defaultClass=true\n"})}),"\n",(0,s.jsx)(n.p,{children:"Verify the pods are up"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"oc get pods\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.em,{children:"EXAMPLE RETURNED OUTPUT HERE"})}),"\n",(0,s.jsx)(n.p,{children:"Make sure the storage class now exists and is set to default"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:"oc get sc\n"})}),"\n",(0,s.jsx)(n.p,{children:"Verify that the storage will provision with the following test deployment"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-tsx",children:'oc apply -f - <<EOF\nkind: Pod\napiVersion: v1\nmetadata:\n  name: test-pod\nspec:\n  containers:\n  - name: test-pod\n    image: busybox:stable\n    command:\n      - "/bin/sh"\n    args:\n      - "-c"\n      - "touch /mnt/SUCCESS && exit 0 || exit 1"\n    volumeMounts:\n      - name: nfs-pvc\n        mountPath: "/mnt"\n  restartPolicy: "Never"\n  volumes:\n    - name: nfs-pvc\n      persistentVolumeClaim:\n        claimName: test-claim\n---\nkind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: test-claim\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 1Mi\nEOF\n'})})]})}function d(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},1151:(e,n,t)=>{t.d(n,{Z:()=>a,a:()=>o});var s=t(7294);const i={},r=s.createContext(i);function o(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);